{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import meteostat as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "# import urllib.parse\n",
    "\n",
    "def get_coordinates(city_name):\n",
    "    # encoded_city = urllib.parse.quote(city_name, safe='')\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    location = geolocator.geocode(city_name)\n",
    "    \n",
    "    if location:\n",
    "        return location.latitude, location.longitude, location. altitude\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_coords(cities_df):\n",
    "    lat, lon = [], []\n",
    "    for search_string in cities_df['string']:\n",
    "        coords = get_coordinates(search_string)\n",
    "        if coords:\n",
    "            lat.append(coords[0])\n",
    "            lon.append(coords[1])\n",
    "        else:\n",
    "            lat.append(np.nan)\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def format_points(points):\n",
    "    points_list = []\n",
    "    for point in points:\n",
    "        points_list.append({\n",
    "            \"latitude\":point[0],\n",
    "            \"longitude\":point[1]\n",
    "        })\n",
    "    return points_list\n",
    "\n",
    "\n",
    "def get_altitudes(points):\n",
    "    formated_points = format_points(points)\n",
    "    url = \"https://api.open-elevation.com/api/v1/lookup\"\n",
    "    data = {\"locations\": formated_points}\n",
    "\n",
    "    response = requests.post(url, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        altitudes = [result.get('elevation', None) for result in results['results']]\n",
    "        return altitudes\n",
    "    else:\n",
    "        print(f\"Failed to fetch altitudes. Status code: {response.status_code}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('city_list.csv')\n",
    "cities['string'] = cities['Cidade'] + ', ' +cities['Estado'] +', Brasil'\n",
    "cities.index.rename('city_id', inplace=True)\n",
    "\n",
    "cities['lat'], cities['lon'] = get_city_coords(cities)\n",
    "cities['Altitude'] = get_altitudes(cities[['lat','lon']].values)\n",
    "cities['geometry'] = gpd.points_from_xy(cities['lon'], cities['lat'], cities['Altitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('city_db.pkl', 'wb') as file:\n",
    "    pickle.dump(cities, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2021/82331.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/82331.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/82331.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2021/83229.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83229.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83229.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/86714.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2021/83376.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83376.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83376.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/81716.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83361.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83361.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2021/83813.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83813.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83813.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/82578.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/82578.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2021/82596.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/82596.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/82596.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/82825.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/82825.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/82024.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/82024.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83897.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83897.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2021/83781.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83781.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83781.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2021/83097.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83097.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83097.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2022/83063.csv.gz from https://bulk.meteostat.net/v2/\n",
      "Warning: Cannot load hourly/2023/83063.csv.gz from https://bulk.meteostat.net/v2/\n"
     ]
    }
   ],
   "source": [
    "# Set time period\n",
    "start = dt.datetime(2021, 1, 1)\n",
    "end = dt.datetime(2023, 10, 31)\n",
    "\n",
    "met_data = {}\n",
    "for city_id, row in cities.iterrows():\n",
    "    met_point = met.Point(row['lat'], row['lon'], row['Altitude'])\n",
    "    met_point.radius = 120000\n",
    "    \n",
    "    data = met.Hourly(met_point, start, end)\n",
    "    data = data.fetch()\n",
    "    \n",
    "    met_data[city_id] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City_id:  0   0.1331020852660025\n",
      "City_id:  1   0.1331020852660025\n",
      "City_id:  2   0.1331020852660025\n",
      "City_id:  3   0.1331020852660025\n",
      "City_id:  4   0.1371354817892147\n",
      "City_id:  5   0.1331020852660025\n",
      "City_id:  6   0.1371354817892147\n",
      "City_id:  7   0.1371354817892147\n",
      "City_id:  8   0.1371354817892147\n",
      "City_id:  9   0.1331020852660025\n",
      "City_id:  10   0.1371354817892147\n",
      "City_id:  11   0.1331020852660025\n",
      "City_id:  12   0.08066793046424393\n",
      "City_id:  13   0.1331020852660025\n",
      "City_id:  14   0.1331020852660025\n",
      "City_id:  15   0.1371354817892147\n",
      "City_id:  16   0.1331020852660025\n",
      "City_id:  17   0.1331020852660025\n",
      "City_id:  18   0.1331020852660025\n",
      "City_id:  19   0.1331020852660025\n",
      "City_id:  20   0.1371354817892147\n",
      "City_id:  21   0.1331020852660025\n",
      "City_id:  22   0.1331020852660025\n",
      "City_id:  23   0.1371354817892147\n",
      "City_id:  24   0.1371354817892147\n",
      "City_id:  25   0.1371354817892147\n",
      "City_id:  26   0.1331020852660025\n"
     ]
    }
   ],
   "source": [
    "for city_id, data in met_data.items():\n",
    "    missing_data = data.isnull().sum() * 100 / len(data)\n",
    "    print('City_id: ',city_id, ' ', missing_data['prcp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('met_data.pkl', 'wb') as file:\n",
    "    pickle.dump(met_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "eda = ProfileReport(data)\n",
    "display(eda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjetoClima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
